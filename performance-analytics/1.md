Performance analytics. 

- 3 Tier Story
A spectrum ranging from lower AI acceleration to more powerful acceleration

    - CPU 
    - GPU - ARC
    - GPU - Gaudi

Demonsrate (before/after)

Entire Solution

- IPEX (Intel PyTorch Extentions) container

    - Inference Container
        - model, inference api
    - upstream available later
    - roll up our application into IPEX

    - Deployments
        - picks CPU/GPU
        - RHEL / Laptop
            - Docker compose
        - RHOAI 
            - OpenVino

- Environments
    - Intel provided RHOAI/OpenShift
        - OpenShift Pod/Deployment/Route


Mini Sprint 1

- generate IPEX model
    - training? dataset? (Sridar / Mrittika)
    - output model
        - test with IPEX inference (docker)
- Integrate @ai-app
    - send json to IPEX
